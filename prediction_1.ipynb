{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# House Prices: Advanced Regression Techniques (Kaggle Competition) - Predictions, 1st Pass"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This notebook follows the process of my first attempt at making predictions from the dataset. For the sake of learning the process end to end, I brushed over some steps that could definitely improve my score, including:\n",
    "\n",
    "* Accounting for multicollinearity\n",
    "* Feature engineering\n",
    "* Feature Selection / Dimensionality Reduction (based on evidence other than what I learned from EDA)\n",
    "* Model Selection\n",
    "\n",
    "I will give these more attention in my next attempt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Get the Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# Having some trouble with Kaggle API at the moment, but in future try to download data programmatically if possible\n",
    "\n",
    "ZIP_PATH = \"data/house-prices-advanced-regression-techniques.zip\"\n",
    "\n",
    "with ZipFile(ZIP_PATH, 'r') as zip:\n",
    "    zip.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "source": [
    "## Data Preparation\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Feature Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We could do more here to select more statistically significant features, but for now I'm going to brush over it for now. I plan on taking the time to learn feature selection methods properly in the near future rather than doing a rushed job of it now. The features I have chosen are the attributes that seem to be promising predictors to me based on the exploratory analysis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[['GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'Fireplaces', 'LotFrontage', 'Neighborhood', 'OverallQual', 'ExterQual', 'BsmtQual', 'KitchenQual']]\n",
    "train_y = train[['SalePrice']]"
   ]
  },
  {
   "source": [
    "### Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1460 entries, 0 to 1459\nData columns (total 13 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   GrLivArea     1460 non-null   int64  \n 1   GarageCars    1460 non-null   int64  \n 2   TotalBsmtSF   1460 non-null   int64  \n 3   FullBath      1460 non-null   int64  \n 4   TotRmsAbvGrd  1460 non-null   int64  \n 5   YearBuilt     1460 non-null   int64  \n 6   Fireplaces    1460 non-null   int64  \n 7   LotFrontage   1201 non-null   float64\n 8   Neighborhood  1460 non-null   object \n 9   OverallQual   1460 non-null   int64  \n 10  ExterQual     1460 non-null   object \n 11  BsmtQual      1423 non-null   object \n 12  KitchenQual   1460 non-null   object \ndtypes: float64(1), int64(8), object(4)\nmemory usage: 148.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_X.info()\n"
   ]
  },
  {
   "source": [
    "There are some null values to deal with. \n",
    "* We will impute `LotFrontage` with the median\n",
    "* The 37 values missing from `BsmtQual` are homes with no basement (there are 37 homes with `TotalBsmtSF` = 0). We will add a new category for these."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "num_features = ['GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'Fireplaces', 'LotFrontage']\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_features = ['Neighborhood']\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "ord_features = ['OverallQual', 'ExterQual', 'BsmtQual', 'KitchenQual']\n",
    "ord_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='NoBsmt')),\n",
    "    ('ordinal', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features),\n",
    "        ('ord', ord_transformer, ord_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_X = preprocessor.fit_transform(train_X)"
   ]
  },
  {
   "source": [
    "## Model Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "I'm still learning about what kind of models work best for different kinds of data, so I'm just going to pick a bunch of models from different categories of approaches for regression and throw the kitchen sink at this."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = [\n",
    "    {'name': 'Linear Regression', 'obj': LinearRegression()},\n",
    "    {'name': 'Stochastic Gradient Descent', 'obj': SGDRegressor()},\n",
    "    {'name': 'K Neighbors Regressor', 'obj': KNeighborsRegressor()},\n",
    "    {'name': 'Decision Tree Regressor', 'obj': DecisionTreeRegressor()},\n",
    "    {'name': 'Random Forest Regressor', 'obj': RandomForestRegressor()},\n",
    "    {'name': 'Kernel Ridge', 'obj': KernelRidge()},\n",
    "    {'name': 'Support Vector Regressor', 'obj': SVR()}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Linear Regression\n",
      "MAE mean: 21696.961362291164\n",
      "MAE Standard deviation: 1142.9194033326394\n",
      "\n",
      "Stochastic Gradient Descent\n",
      "MAE mean: 25152.581616050975\n",
      "MAE Standard deviation: 1372.4404521678796\n",
      "\n",
      "K Neighbors Regressor\n",
      "MAE mean: 21399.802054794523\n",
      "MAE Standard deviation: 1746.853116148743\n",
      "\n",
      "Decision Tree Regressor\n",
      "MAE mean: 27881.964155251142\n",
      "MAE Standard deviation: 2503.2013973197954\n",
      "\n",
      "Random Forest Regressor\n",
      "MAE mean: 19346.336112720157\n",
      "MAE Standard deviation: 1101.763148260912\n",
      "\n",
      "Kernel Ridge\n",
      "MAE mean: 23597.89819824807\n",
      "MAE Standard deviation: 1279.337005615513\n",
      "\n",
      "Support Vector Regressor\n",
      "MAE mean: 55473.54456463078\n",
      "MAE Standard deviation: 3359.595186863918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "for mdl in models:  \n",
    "    cv_mae = cross_val_score(mdl['obj'], train_X, train_y, cv=5, scoring='neg_mean_absolute_error')\n",
    "    print()\n",
    "    print(mdl['name'])\n",
    "    print(\"MAE mean:\", -(cv_mae.mean()))\n",
    "    print(\"MAE Standard deviation:\", cv_mae.std())"
   ]
  },
  {
   "source": [
    "## Model Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'bootstrap': True,\n 'ccp_alpha': 0.0,\n 'criterion': 'mse',\n 'max_depth': None,\n 'max_features': 'auto',\n 'max_leaf_nodes': None,\n 'max_samples': None,\n 'min_impurity_decrease': 0.0,\n 'min_impurity_split': None,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 100,\n 'n_jobs': None,\n 'oob_score': False,\n 'random_state': 33,\n 'verbose': 0,\n 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "rfr = RandomForestRegressor(random_state=33)\n",
    "pprint(rfr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=33),\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [25, 30, 60, 120],\n",
       "                         'max_features': [5, 6],\n",
       "                         'n_estimators': [250, 300, 350, 400]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# I tried multiple different grids to achieve a better score, refining the parameters with each iteration. These are the last set I tried\n",
    "param_grid = {   \n",
    "        'bootstrap': [True],\n",
    "        'n_estimators': [250, 300, 350, 400], \n",
    "        'max_features': [5, 6], \n",
    "        'max_depth': [25, 30, 60, 120],\n",
    "}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=33)\n",
    "grid_search = GridSearchCV(rfr, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'bootstrap': True, 'max_depth': 30, 'max_features': 5, 'n_estimators': 300}\n-18193.76072973703\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "source": [
    "## Make Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([119257.28111111, 152035.03      , 177325.24166667, ...,\n",
       "       160348.49333333, 115330.23333333, 222651.78      ])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "mdl_final = grid_search.best_estimator_\n",
    "\n",
    "test_X = test # the target variable has already been removed from the test set provided by kaggle\n",
    "\n",
    "test_X = preprocessor.fit_transform(test_X)\n",
    "predictions = mdl_final.predict(test_X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dict = {'Id': test['Id'], 'SalePrice': predictions}\n",
    "submission_df = pd.DataFrame(data=submission_dict)\n",
    "submission_df.to_csv('predictions_1.csv', index=False)"
   ]
  }
 ]
}