{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# House Prices: Advanced Regression Techniques (Kaggle Competition) - Predictions, 1st Pass"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Get the Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# Having some trouble with Kaggle API at the moment, but in future try to download data programmatically if possible\n",
    "\n",
    "ZIP_PATH = \"data/house-prices-advanced-regression-techniques.zip\"\n",
    "\n",
    "with ZipFile(ZIP_PATH, 'r') as zip:\n",
    "    zip.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "source": [
    "## Data Preparation\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Feature Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[['GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt', 'Neighborhood', 'OverallQual', 'ExterQual', 'BsmtQual', 'KitchenQual']]\n",
    "train_y = train[['SalePrice']]"
   ]
  },
  {
   "source": [
    "### Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1460 entries, 0 to 1459\nData columns (total 10 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   GrLivArea     1460 non-null   int64 \n 1   GarageCars    1460 non-null   int64 \n 2   TotalBsmtSF   1460 non-null   int64 \n 3   FullBath      1460 non-null   int64 \n 4   YearBuilt     1460 non-null   int64 \n 5   Neighborhood  1460 non-null   object\n 6   OverallQual   1460 non-null   int64 \n 7   ExterQual     1460 non-null   object\n 8   BsmtQual      1423 non-null   object\n 9   KitchenQual   1460 non-null   object\ndtypes: int64(6), object(4)\nmemory usage: 114.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_X.info()\n"
   ]
  },
  {
   "source": [
    "There are some null values to deal with. \n",
    "* We will impute `LotFrontage` with the median\n",
    "* The 37 values missing from `BsmtQual` are homes with no basement (there are 37 homes with `TotalBsmtSF` = 0). We will add a new category for these."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "num_features = ['GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_features = ['Neighborhood']\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "ord_features = ['OverallQual', 'ExterQual', 'BsmtQual', 'KitchenQual']\n",
    "ord_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='NoBsmt')),\n",
    "    ('ordinal', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features),\n",
    "        ('ord', ord_transformer, ord_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_X = preprocessor.fit_transform(train_X)"
   ]
  },
  {
   "source": [
    "## Model Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = [\n",
    "    {'name': 'Linear Regression', 'obj': LinearRegression()},\n",
    "    {'name': 'Stochastic Gradient Descent', 'obj': SGDRegressor()},\n",
    "    {'name': 'K Neighbors Regressor', 'obj': KNeighborsRegressor()},\n",
    "    {'name': 'Decision Tree Regressor', 'obj': DecisionTreeRegressor()},\n",
    "    {'name': 'Random Forest Regressor', 'obj': RandomForestRegressor()},\n",
    "    {'name': 'Gradient Boosting Regressor', 'obj': GradientBoostingRegressor()},\n",
    "    {'name': 'Kernel Ridge', 'obj': KernelRidge()},\n",
    "    {'name': 'Support Vector Regressor', 'obj': SVR()}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Linear Regression\n",
      "MAE mean: 21765.337509236742\n",
      "MAE Standard deviation: 999.5519134016062\n",
      "\n",
      "Stochastic Gradient Descent\n",
      "MAE mean: 25861.963185276127\n",
      "MAE Standard deviation: 1394.4158238637972\n",
      "\n",
      "K Neighbors Regressor\n",
      "MAE mean: 21252.800000000003\n",
      "MAE Standard deviation: 1562.2850121773479\n",
      "\n",
      "Decision Tree Regressor\n",
      "MAE mean: 27108.26335616438\n",
      "MAE Standard deviation: 2808.054044298283\n",
      "\n",
      "Random Forest Regressor\n",
      "MAE mean: 19430.68905264929\n",
      "MAE Standard deviation: 1338.5480735133265\n",
      "\n",
      "Gradient Boosting Regressor\n",
      "MAE mean: 19107.70940611959\n",
      "MAE Standard deviation: 969.1644753522263\n",
      "\n",
      "Kernel Ridge\n",
      "MAE mean: 23574.102265299924\n",
      "MAE Standard deviation: 1246.27711528727\n",
      "\n",
      "Support Vector Regressor\n",
      "MAE mean: 55472.38517888852\n",
      "MAE Standard deviation: 3360.014995497445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "for mdl in models:  \n",
    "    cv_mae = cross_val_score(mdl['obj'], train_X, train_y, cv=5, scoring='neg_mean_absolute_error')\n",
    "    print()\n",
    "    print(mdl['name'])\n",
    "    print(\"MAE mean:\", -(cv_mae.mean()))\n",
    "    print(\"MAE Standard deviation:\", cv_mae.std())"
   ]
  },
  {
   "source": [
    "## Model Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Random Forrest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'bootstrap': True,\n 'ccp_alpha': 0.0,\n 'criterion': 'mse',\n 'max_depth': None,\n 'max_features': 'auto',\n 'max_leaf_nodes': None,\n 'max_samples': None,\n 'min_impurity_decrease': 0.0,\n 'min_impurity_split': None,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 100,\n 'n_jobs': None,\n 'oob_score': False,\n 'random_state': 33,\n 'verbose': 0,\n 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "rfr = RandomForestRegressor(random_state=33)\n",
    "pprint(rfr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=33),\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [25, 30, 60, 120],\n",
       "                         'max_features': [5, 6],\n",
       "                         'n_estimators': [250, 300, 350, 400]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# I tried multiple different grids to achieve a better score, refining the parameters with each iteration. These are the last set I tried\n",
    "param_grid = {   \n",
    "        'bootstrap': [True],\n",
    "        'n_estimators': [300, 350, 400], \n",
    "        'max_features': [4, 5, 6], \n",
    "        'max_depth': [45, 60, 75, 90],\n",
    "}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=33)\n",
    "grid_search_rfr = GridSearchCV(rfr, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search_rfr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'bootstrap': True, 'max_depth': 60, 'max_features': 5, 'n_estimators': 350}\n-18555.832468009008\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rfr.best_params_)\n",
    "print(grid_search_rfr.best_score_)"
   ]
  },
  {
   "source": [
    "### Gradient Boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'alpha': 0.9,\n 'ccp_alpha': 0.0,\n 'criterion': 'friedman_mse',\n 'init': None,\n 'learning_rate': 0.1,\n 'loss': 'ls',\n 'max_depth': 3,\n 'max_features': None,\n 'max_leaf_nodes': None,\n 'min_impurity_decrease': 0.0,\n 'min_impurity_split': None,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 100,\n 'n_iter_no_change': None,\n 'presort': 'deprecated',\n 'random_state': 33,\n 'subsample': 1.0,\n 'tol': 0.0001,\n 'validation_fraction': 0.1,\n 'verbose': 0,\n 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "rfr = GradientBoostingRegressor(random_state=33)\n",
    "pprint(rfr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=33),\n",
       "             param_grid={'learning_rate': [0.015, 0.025, 0.05],\n",
       "                         'max_depth': [4, 5], 'max_features': [4, 5],\n",
       "                         'n_estimators': [1000, 1100, 1500, 2000]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "        'n_estimators': [1000, 1100, 1500, 2000], \n",
    "        'max_features': [4, 5], \n",
    "        'max_depth': [4, 5],\n",
    "        'learning_rate': [0.015, 0.025, 0.05]\n",
    "}\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=33)\n",
    "grid_search_gbr = GridSearchCV(gbr, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search_gbr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'learning_rate': 0.025, 'max_depth': 4, 'max_features': 5, 'n_estimators': 1100}\n-17870.03787211852\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_gbr.best_params_)\n",
    "print(grid_search_gbr.best_score_)"
   ]
  },
  {
   "source": [
    "## Make Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([113213.68      , 153577.42857143, 174398.93047619, ...,\n",
       "       139686.64285714, 108664.36190476, 214233.14      ])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "mdl_final = grid_search_rfr.best_estimator_\n",
    "\n",
    "test_X = test # the target variable has already been removed from the test set provided by kaggle\n",
    "\n",
    "test_X = preprocessor.fit_transform(test_X)\n",
    "predictions = mdl_final.predict(test_X)\n",
    "predictions"
   ]
  },
  {
   "source": [
    "### Gradient Boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([123053.69055576, 158012.68480855, 173995.52942848, ...,\n",
       "       147323.36093092, 116961.17067593, 217186.63168137])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "mdl_final = grid_search_gbr.best_estimator_\n",
    "\n",
    "test_X = test # the target variable has already been removed from the test set provided by kaggle\n",
    "\n",
    "test_X = preprocessor.fit_transform(test_X)\n",
    "predictions = mdl_final.predict(test_X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dict = {'Id': test['Id'], 'SalePrice': predictions}\n",
    "submission_df = pd.DataFrame(data=submission_dict)\n",
    "submission_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ]
}