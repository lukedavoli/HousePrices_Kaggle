{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# House Prices: Advanced Regression Techniques (Kaggle Competition) - Predictions, 1st Pass"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Get the Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# Having some trouble with Kaggle API at the moment, but in future try to download data programmatically if possible\n",
    "\n",
    "ZIP_PATH = \"data/house-prices-advanced-regression-techniques.zip\"\n",
    "\n",
    "with ZipFile(ZIP_PATH, 'r') as zip:\n",
    "    zip.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "source": [
    "## Data Preparation\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Feature Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from bivariate analysis of GrLivArea vs SalePrice\n",
    "# train = train[train['GrLivArea'] < 4500]\n",
    "# This helped my score on cross validation but worsened my final test score so I've commented it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[['GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt', 'Neighborhood', 'OverallQual', 'ExterQual', 'BsmtQual', 'KitchenQual']]\n",
    "train_y = train[['SalePrice']]"
   ]
  },
  {
   "source": [
    "### Data Preprocessing (remove outliers, impute missing values, standardize and encode data)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1460 entries, 0 to 1459\nData columns (total 10 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   GrLivArea     1460 non-null   int64 \n 1   GarageCars    1460 non-null   int64 \n 2   TotalBsmtSF   1460 non-null   int64 \n 3   FullBath      1460 non-null   int64 \n 4   YearBuilt     1460 non-null   int64 \n 5   Neighborhood  1460 non-null   object\n 6   OverallQual   1460 non-null   int64 \n 7   ExterQual     1460 non-null   object\n 8   BsmtQual      1423 non-null   object\n 9   KitchenQual   1460 non-null   object\ndtypes: int64(6), object(4)\nmemory usage: 114.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_X.info()\n"
   ]
  },
  {
   "source": [
    "There are some null values to deal with. \n",
    "* We will impute `LotFrontage` with the median\n",
    "* The 37 values missing from `BsmtQual` are homes with no basement (there are 37 homes with `TotalBsmtSF` = 0). We will add a new category for these."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "num_features = ['GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_features = ['Neighborhood']\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "ord_features = ['OverallQual', 'ExterQual', 'BsmtQual', 'KitchenQual']\n",
    "ord_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='NoBsmt')),\n",
    "    ('ordinal', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features),\n",
    "        ('ord', ord_transformer, ord_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_X = preprocessor.fit_transform(train_X)"
   ]
  },
  {
   "source": [
    "## Model Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = [\n",
    "    {'name': 'Linear Regression', 'obj': LinearRegression()},\n",
    "    {'name': 'Stochastic Gradient Descent', 'obj': SGDRegressor()},\n",
    "    {'name': 'K Neighbors Regressor', 'obj': KNeighborsRegressor()},\n",
    "    {'name': 'Decision Tree Regressor', 'obj': DecisionTreeRegressor()},\n",
    "    {'name': 'Random Forest Regressor', 'obj': RandomForestRegressor()},\n",
    "    {'name': 'Gradient Boosting Regressor', 'obj': GradientBoostingRegressor()},\n",
    "    {'name': 'XGBoost', 'obj': XGBRegressor()},\n",
    "    {'name': 'Kernel Ridge', 'obj': KernelRidge()},\n",
    "    {'name': 'Support Vector Regressor', 'obj': SVR()}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Linear Regression\n",
      "MAE mean: 21765.337509236742\n",
      "MAE Standard deviation: 999.5519134016062\n",
      "\n",
      "Stochastic Gradient Descent\n",
      "MAE mean: 26046.499566542374\n",
      "MAE Standard deviation: 1318.8172481831807\n",
      "\n",
      "K Neighbors Regressor\n",
      "MAE mean: 21252.800000000003\n",
      "MAE Standard deviation: 1562.2850121773479\n",
      "\n",
      "Decision Tree Regressor\n",
      "MAE mean: 26533.03595890411\n",
      "MAE Standard deviation: 2485.125712422217\n",
      "\n",
      "Random Forest Regressor\n",
      "MAE mean: 19564.329108013597\n",
      "MAE Standard deviation: 1268.0813798307554\n",
      "\n",
      "Gradient Boosting Regressor\n",
      "MAE mean: 19042.400500172924\n",
      "MAE Standard deviation: 892.9086546588333\n",
      "\n",
      "XGBoost\n",
      "MAE mean: 20308.317513912676\n",
      "MAE Standard deviation: 1680.6798919034466\n",
      "\n",
      "Kernel Ridge\n",
      "MAE mean: 23574.102265299924\n",
      "MAE Standard deviation: 1246.27711528727\n",
      "\n",
      "Support Vector Regressor\n",
      "MAE mean: 55472.38517888852\n",
      "MAE Standard deviation: 3360.014995497445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "for mdl in models:  \n",
    "    cv_mae = cross_val_score(mdl['obj'], train_X, train_y, cv=5, scoring='neg_mean_absolute_error')\n",
    "    print()\n",
    "    print(mdl['name'])\n",
    "    print(\"MAE mean:\", -(cv_mae.mean()))\n",
    "    print(\"MAE Standard deviation:\", cv_mae.std())"
   ]
  },
  {
   "source": [
    "## Model Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'bootstrap': True,\n 'ccp_alpha': 0.0,\n 'criterion': 'mse',\n 'max_depth': None,\n 'max_features': 'auto',\n 'max_leaf_nodes': None,\n 'max_samples': None,\n 'min_impurity_decrease': 0.0,\n 'min_impurity_split': None,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 100,\n 'n_jobs': None,\n 'oob_score': False,\n 'random_state': 33,\n 'verbose': 0,\n 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "rfr = RandomForestRegressor(random_state=33)\n",
    "pprint(rfr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=33),\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [45, 60, 75, 90],\n",
       "                         'max_features': [4, 5, 6],\n",
       "                         'n_estimators': [300, 350, 400]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# I tried multiple different grids to achieve a better score, refining the parameters with each iteration. These are the last set I tried\n",
    "param_grid = {   \n",
    "        'bootstrap': [True],\n",
    "        'n_estimators': [300, 350, 400], \n",
    "        'max_features': [4, 5, 6], \n",
    "        'max_depth': [45, 60, 75, 90],\n",
    "}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=33)\n",
    "grid_search_rfr = GridSearchCV(rfr, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=6)\n",
    "grid_search_rfr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'bootstrap': True, 'max_depth': 45, 'max_features': 6, 'n_estimators': 350}\n-18299.24061890085\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rfr.best_params_)\n",
    "print(grid_search_rfr.best_score_)"
   ]
  },
  {
   "source": [
    "### Gradient Boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'alpha': 0.9,\n 'ccp_alpha': 0.0,\n 'criterion': 'friedman_mse',\n 'init': None,\n 'learning_rate': 0.1,\n 'loss': 'ls',\n 'max_depth': 3,\n 'max_features': None,\n 'max_leaf_nodes': None,\n 'min_impurity_decrease': 0.0,\n 'min_impurity_split': None,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 100,\n 'n_iter_no_change': None,\n 'presort': 'deprecated',\n 'random_state': 33,\n 'subsample': 1.0,\n 'tol': 0.0001,\n 'validation_fraction': 0.1,\n 'verbose': 0,\n 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "rfr = GradientBoostingRegressor(random_state=33)\n",
    "pprint(rfr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=33),\n",
       "             param_grid={'learning_rate': [0.015, 0.025, 0.05],\n",
       "                         'max_depth': [4, 5], 'max_features': [4, 5],\n",
       "                         'n_estimators': [1000, 1100, 1500, 2000]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "        'n_estimators': [1000, 1100, 1500, 2000], \n",
    "        'max_features': [4, 5], \n",
    "        'max_depth': [4, 5],\n",
    "        'learning_rate': [0.015, 0.025, 0.05]\n",
    "}\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=33)\n",
    "grid_search_gbr = GridSearchCV(gbr, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=6)\n",
    "grid_search_gbr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'learning_rate': 0.015, 'max_depth': 4, 'max_features': 5, 'n_estimators': 1500}\n-17501.519157536157\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_gbr.best_params_)\n",
    "print(grid_search_gbr.best_score_)"
   ]
  },
  {
   "source": [
    "### XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'base_score': None,\n 'booster': None,\n 'colsample_bylevel': None,\n 'colsample_bynode': None,\n 'colsample_bytree': None,\n 'gamma': None,\n 'gpu_id': None,\n 'importance_type': 'gain',\n 'interaction_constraints': None,\n 'learning_rate': None,\n 'max_delta_step': None,\n 'max_depth': None,\n 'min_child_weight': None,\n 'missing': nan,\n 'monotone_constraints': None,\n 'n_estimators': 100,\n 'n_jobs': None,\n 'num_parallel_tree': None,\n 'objective': 'reg:squarederror',\n 'random_state': 33,\n 'reg_alpha': None,\n 'reg_lambda': None,\n 'scale_pos_weight': None,\n 'subsample': None,\n 'tree_method': None,\n 'validate_parameters': None,\n 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "xgb = XGBRegressor(random_state=33)\n",
    "pprint(xgb.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=33),\n",
       "             n_jobs=6,\n",
       "             param_grid={'learning_rate': [0.2, 0.3, 0.4, 0.8],\n",
       "                         'n_estimators': [125, 100, 125]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "        'n_estimators': [125, 100, 125],\n",
    "        'learning_rate': [0.2, 0.3, 0.4, 0.8]\n",
    "}\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=33)\n",
    "grid_search_xgb = GridSearchCV(gbr, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=6)\n",
    "grid_search_xgb.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'learning_rate': 0.2, 'n_estimators': 125}\n-18586.02242074211\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_xgb.best_params_)\n",
    "print(grid_search_xgb.best_score_)"
   ]
  },
  {
   "source": [
    "## Make Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([112943.61619048, 154828.71428571, 172441.43428571, ...,\n",
       "       141400.99428571, 106869.33333333, 210524.66      ])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "mdl_final = grid_search_rfr.best_estimator_\n",
    "\n",
    "test_X = test # the target variable has already been removed from the test set provided by kaggle\n",
    "\n",
    "test_X = preprocessor.fit_transform(test_X)\n",
    "predictions = mdl_final.predict(test_X)\n",
    "predictions"
   ]
  },
  {
   "source": [
    "### Gradient Boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([124099.13779855, 156702.78084556, 172073.44575827, ...,\n",
       "       146248.53243224, 118460.76941357, 215356.59828922])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "mdl_final = grid_search_gbr.best_estimator_\n",
    "\n",
    "test_X = test # the target variable has already been removed from the test set provided by kaggle\n",
    "\n",
    "test_X = preprocessor.fit_transform(test_X)\n",
    "predictions = mdl_final.predict(test_X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([123355.39968837, 156199.76444146, 163199.05083515, ...,\n",
       "       144774.17875048, 119185.63634525, 239402.15948509])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "mdl_final = grid_search_xgb.best_estimator_\n",
    "\n",
    "test_X = test # the target variable has already been removed from the test set provided by kaggle\n",
    "\n",
    "test_X = preprocessor.fit_transform(test_X)\n",
    "predictions = mdl_final.predict(test_X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dict = {'Id': test['Id'], 'SalePrice': predictions}\n",
    "submission_df = pd.DataFrame(data=submission_dict)\n",
    "submission_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}